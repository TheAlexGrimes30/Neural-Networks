{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ed6361",
   "metadata": {},
   "source": [
    "### Гопиенко Александр Дмитриевич КИ22-17/2Б\n",
    "\n",
    "# Практическая работа №4 по реккурентным нейронным сетям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c1f5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4115f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITIES = {\n",
    "    1: 'WALKING',\n",
    "    2: 'WALKING_UPSTAIRS',\n",
    "    3: 'WALKING_DOWNSTAIRS',\n",
    "    4: 'SITTING',\n",
    "    5: 'STANDING',\n",
    "    6: 'LAYING',\n",
    "}\n",
    "\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0567e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI HAR dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).to_numpy()\n",
    "        )\n",
    "\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    filename = f'UCI HAR dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).to_numpy()\n",
    "\n",
    "def load_data():\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def plot_train_val_accuracy_loss(history):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb3fe396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13360\\1713751055.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(filename, delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7ed873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a619b",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e273c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = CustomDataset(X_train, Y_train)\n",
    "test_dataset = CustomDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5b573",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32acb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d648a",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44788312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef83302",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158fa09",
   "metadata": {},
   "source": [
    "# Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRnnClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, n_classes):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b49a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = torch.argmax(y, dim=1)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe1f19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = torch.argmax(y, dim=1)\n",
    "\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return total_loss / len(val_loader), correct / total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 18:31:41,900] A new study created in memory with name: no-name-a918b557-2520-4cc0-a5d0-5237bd9e44b3\n",
      "Training: 100%|██████████| 10/10 [00:37<00:00,  3.77s/it]\n",
      "[I 2025-04-26 18:32:19,568] Trial 0 finished with value: 1.203473840349464 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'lr': 0.0001, 'optimizer': 'Adam'}. Best is trial 0 with value: 1.203473840349464.\n",
      "Training:  70%|███████   | 7/10 [01:26<00:37, 12.42s/it]\n",
      "[I 2025-04-26 18:33:46,546] Trial 1 finished with value: 0.7647518818416903 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'lr': 0.001, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.7647518818416903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping on epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [01:19<00:00,  7.96s/it]\n",
      "[I 2025-04-26 18:35:06,177] Trial 2 finished with value: 1.7963588929945422 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'lr': 0.0001, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.7647518818416903.\n",
      "Training: 100%|██████████| 10/10 [01:19<00:00,  7.99s/it]\n",
      "[I 2025-04-26 18:36:26,106] Trial 3 finished with value: 1.1074553410452541 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'lr': 0.0001, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.7647518818416903.\n",
      "Training: 100%|██████████| 10/10 [00:36<00:00,  3.69s/it]\n",
      "[I 2025-04-26 18:37:03,058] Trial 4 finished with value: 1.454681348095658 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'lr': 0.001, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.7647518818416903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'hidden_dim': 128, 'num_layers': 2, 'lr': 0.001, 'optimizer': 'Adam'}\n",
      "Best score: 0.7647518818416903\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, model_option=\"rnn\"):\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_categorical('lr', [1e-4, 1e-3, 1e-2])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "    if model_option == \"rnn\":\n",
    "        model = RNNClassifier(input_dim, hidden_dim, num_layers, n_classes).to(device)\n",
    "    elif model_option == \"lstm\":\n",
    "        model = LstmClassifier(input_dim, hidden_dim, num_layers, n_classes).to(device)\n",
    "    elif model_option == \"gru\":\n",
    "        model = GruClassifier(input_dim, hidden_dim, num_layers, n_classes).to(device)\n",
    "    elif model_option == \"brnn\":\n",
    "        model = BRnnClassifier(input_dim, hidden_dim, num_layers, n_classes).to(device)\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5 \n",
    "    counter = 0\n",
    "\n",
    "    for epoch in tqdm(range(10), desc=\"Training\"):  \n",
    "        train_loss = train(model, optimizer, criterion, train_loader, device)\n",
    "        val_loss, val_acc = evaluate(model, criterion, test_loader, device)\n",
    "\n",
    "        trial.report(val_loss, epoch)  \n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping on epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        if trial.should_prune():  \n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d0c43",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f949aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, model_option=\"rnn\")  \n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2186826",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, model_option=\"lstm\")  \n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49360d",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb453eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, model_option=\"gru\")  \n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009f401",
   "metadata": {},
   "source": [
    "# Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9000ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, model_option=\"brnn\")  \n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best score:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
